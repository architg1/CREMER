{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREMER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/architg/miniforge3/envs/tf_m1/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import sklearn \n",
    "import imblearn\n",
    "import time\n",
    "import xgboost\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "from sklearn.metrics import recall_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Number   Lon (deg)  Lat (deg)        Alt (m)  Timestamp (ms UTC Unix)  \\\n",
      "72824    72825  -42.088117 -16.628635  599378.852916            1509637385920   \n",
      "171397  171398   57.456147 -55.080587  608985.955780            1514945766849   \n",
      "159840  159841  -76.178403   7.098535  588791.475168            1526434315228   \n",
      "163698  163699 -146.341418 -42.538171  606205.646457            1526528880748   \n",
      "104458  104459  -92.685061  -9.465018  578391.180429            1503760506593   \n",
      "92315    92316  -56.322774  -4.473178  602205.721654            1506819921389   \n",
      "85587    85588  -11.180755 -70.399523  585849.498499            1521035871786   \n",
      "14062    14063  -69.886821  55.783444  581672.284835            1514006861799   \n",
      "139804  139805  -90.611845  41.520454  601668.680989            1522563752308   \n",
      "83325    83326  148.047553  72.184514  603603.421205            1504663466253   \n",
      "\n",
      "       Time Position Source  SEU  \n",
      "72824   NaN             NaN    0  \n",
      "171397  NaN             NaN    0  \n",
      "159840  NaN             NaN    0  \n",
      "163698  NaN             NaN    0  \n",
      "104458  NaN             NaN    0  \n",
      "92315   NaN             NaN    0  \n",
      "85587   NaN             NaN    0  \n",
      "14062   NaN             NaN    0  \n",
      "139804  NaN             NaN    0  \n",
      "83325   NaN             NaN    0  \n",
      "\n",
      "\n",
      "Number of samples:  1599992\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('SEU Occurance Dataset.csv')\n",
    "print(df.sample(n=10))\n",
    "print('\\n')\n",
    "print('Number of samples: ', df.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Number  Lon (deg)  Lat (deg)        Alt (m)  Timestamp (ms UTC Unix)  \\\n",
      "0       1 -53.718376  79.695173  617150.437500            1527486385447   \n",
      "1       2 -53.718376  79.695173  617150.437500            1527486385447   \n",
      "2       3 -24.780551  82.160168  617444.375000            1527486303841   \n",
      "3       4 -38.133264 -19.880011  596665.263226            1527470646745   \n",
      "4       5 -45.491699 -80.723138  599915.022891            1527442867944   \n",
      "5       6 -64.639836 -39.309800  602378.198659            1527389777008   \n",
      "6       7 -63.863840 -36.600821  588964.257895            1527389732796   \n",
      "7       8 -63.863840 -36.600821  588964.257895            1527389732796   \n",
      "8       9 -39.735791 -36.724916  589059.315441            1527383935948   \n",
      "9      10  30.074085  52.083323  607484.076194            1527370896476   \n",
      "\n",
      "                  Time Position Source  SEU  \n",
      "0  2018-05-28T05:46:25             TLE    1  \n",
      "1  2018-05-28T05:46:25             TLE    1  \n",
      "2  2018-05-28T05:45:03             TLE    1  \n",
      "3  2018-05-28T01:24:06         onboard    1  \n",
      "4  2018-05-27T17:41:07         onboard    1  \n",
      "5  2018-05-27T02:56:17         onboard    1  \n",
      "6  2018-05-27T02:55:32         onboard    1  \n",
      "7  2018-05-27T02:55:32         onboard    1  \n",
      "8  2018-05-27T01:18:55         onboard    1  \n",
      "9  2018-05-26T21:41:36         onboard    1  \n"
     ]
    }
   ],
   "source": [
    "print(df.head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    197870\n",
       "1      2129\n",
       "Name: SEU, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SEU'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.asanyarray(df[['Lon (deg)', 'Lat (deg)', 'Alt (m)']])\n",
    "y = np.asanyarray(df[['SEU']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159999\n"
     ]
    }
   ],
   "source": [
    "print(y_train.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3392\n",
      "Counter({0: 1696, 1: 1696})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "oversample = SMOTE()\n",
    "undersample = ClusterCentroids(voting = 'soft') # soft as we ourselves augmented the data\n",
    "combine = SMOTEENN()\n",
    "\n",
    "x_train, y_train = undersample.fit_resample(x_train, y_train)\n",
    "print(y_train.size)\n",
    "print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_classificationReport(y, y_hat):\n",
    "    print('Balanced Accuracy Score: ', sklearn.metrics.balanced_accuracy_score(y, y_hat))\n",
    "    print('\\n')\n",
    "    print(classification_report(y, y_hat))\n",
    "    CM = confusion_matrix(y, y_hat)\n",
    "    print(CM)\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    tn, fp, fn, tp = CM.ravel()\n",
    "    print('True Negative:' ,tn)\n",
    "    print('False Negative:', fn)\n",
    "    print('True Positive:' ,tp)\n",
    "    print('False Positive:', fp)\n",
    "    print('Recall: ', recall_score(y, y_hat))\n",
    "    print('ROC AUC Score: ', sklearn.metrics.roc_auc_score(y, y_hat))\n",
    "    # Positive is SEU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREMER Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(class_weight = {0:1, 1:100},\n",
    "                                min_samples_leaf = 8,\n",
    "                               )\n",
    "\n",
    "clf_xgb = XGBClassifier(booster = 'gbtree',\n",
    "                        gamma = 0.01,\n",
    "                        min_child_weight = 1, # as the data is highly imbalanced, leaf nodes can have smaller sized groups\n",
    "                        max_delta_step = 1, \n",
    "                        objective = 'reg:squaredlogerror',\n",
    "                        scale_pos_weight = 100, # to control the balance of pos and neg weight, = #neg/#pos\n",
    "                        # predictor = 'gpu_predictor',\n",
    "                        use_label_encoder = False,\n",
    "                        verbosity = 0\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "estimator = []\n",
    "estimator.append(('XGBoost', clf_xgb))\n",
    "estimator.append(('Random Forest', clf_rf))\n",
    "\n",
    "clf_voting = VotingClassifier(estimators = estimator, voting = 'soft')\n",
    "clf_voting.fit(x_train, y_train)\n",
    "y_hat_voting = clf_voting.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy Score:  0.6279925341941995\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.30      0.46     39567\n",
      "           1       0.01      0.96      0.03       433\n",
      "\n",
      "    accuracy                           0.30     40000\n",
      "   macro avg       0.51      0.63      0.24     40000\n",
      "weighted avg       0.99      0.30      0.45     40000\n",
      "\n",
      "[[11682 27885]\n",
      " [   17   416]]\n",
      "True Negative: 11682\n",
      "False Negative: 17\n",
      "True Positive: 416\n",
      "False Positive: 27885\n",
      "Recall:  0.9607390300230947\n",
      "ROC AUC Score:  0.6279925341941995\n"
     ]
    }
   ],
   "source": [
    "evaluation_classificationReport(y_test, y_hat_voting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make A Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-SEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data point: [-4.80081543e+01  2.85151453e+01  5.93768858e+05]\n"
     ]
    }
   ],
   "source": [
    "print('Data point:', x_test[890])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True value: 0\n",
      "Predicted value: 0\n"
     ]
    }
   ],
   "source": [
    "print('True value:', y_test[809][0])\n",
    "print('Predicted value:', y_hat_voting[809])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data point: [-1.04219427e+02  7.37542178e+01  5.97760826e+05]\n"
     ]
    }
   ],
   "source": [
    "print('Data point:', x_test[89])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True value: 1\n",
      "Predicted value: 1\n"
     ]
    }
   ],
   "source": [
    "print('True value:', y_test[89][0])\n",
    "print('Predicted value:', y_hat_voting[89])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = []\n",
    "precision = []\n",
    "f1 = []\n",
    "aucroc = []\n",
    "timer = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "for i in range(1):\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "\n",
    "    \n",
    "    from imblearn.under_sampling import ClusterCentroids\n",
    "    undersample = ClusterCentroids(voting = 'soft') # soft as we ourselves augmented the data\n",
    "    x_train, y_train = undersample.fit_resample(x_train, y_train)\n",
    "    \n",
    "    from sklearn.ensemble import VotingClassifier\n",
    "    estimator = []\n",
    "    estimator.append(('XGBoost', clf_xgb))\n",
    "    estimator.append(('Random Forest', clf_rf))\n",
    "\n",
    "    clf_voting = VotingClassifier(estimators = estimator, voting = 'soft')\n",
    "    clf_voting.fit(x_train, y_train)\n",
    "    start = time.time()\n",
    "    y_hat_voting = clf_voting.predict(x_test)\n",
    "    end = time.time()\n",
    "    \n",
    "    recall.append(sklearn.metrics.recall_score(y_test, y_hat_voting))\n",
    "    precision.append(sklearn.metrics.precision_score(y_test, y_hat_voting))\n",
    "    f1.append(sklearn.metrics.f1_score(y_test, y_hat_voting))\n",
    "    aucroc.append(sklearn.metrics.roc_auc_score(y_test, y_hat_voting))\n",
    "    timer.append(end-start)\n",
    "    print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Recall: ', sum(recall)/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1: ', sum(f1)/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision: ', sum(precision)/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('AUC: ', sum(aucroc)/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Time: ', sum(timer)/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
